{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle8k_VGG16pretrain.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "9YsQvqoByt3g",
        "colab_type": "code",
        "outputId": "c80b7ba9-be3f-4644-85da-e64b26a82e63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "cell_type": "code",
      "source": [
        "##### loading data #####\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 4 classes.\n",
            "Found 32 images belonging to 4 classes.\n",
            "Found 968 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YPs775E-fo0p",
        "colab_type": "code",
        "outputId": "2bb2241d-d3b8-4b85-db1e-ae8a51ad9689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "train_dir = \"/gdrive/My Drive/kaggle_dataset/train/\"\n",
        "val_dir = \"/gdrive/My Drive/kaggle_dataset/val/\"\n",
        "test_dir = \"/gdrive/My Drive/kaggle_dataset/test/\"\n",
        "\n",
        "img_width = 224\n",
        "img_height = 224\n",
        "\n",
        "# img_width = 512\n",
        "# img_height = 496\n",
        "\n",
        "batch_size = 128\n",
        "channels = 3\n",
        "epochs = 50\n",
        "nb_train_samples = 8000\n",
        "nb_valid_samples = 32\n",
        "nb_test_samples = 968\n",
        "num_classes = 4\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)             \n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)    \n",
        "test_datagen = ImageDataGenerator(rescale=1./255) \n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, \n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True)   \n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True) #weight toward one class or another\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 4 classes.\n",
            "Found 32 images belonging to 4 classes.\n",
            "Found 968 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Stf1qT-VXxPT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Softmax, Flatten, Dense, BatchNormalization \n",
        "from keras.metrics import categorical_accuracy\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from PIL import Image\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "from keras import layers\n",
        "from keras.callbacks import TensorBoard, Callback\n",
        "from keras.applications import VGG16, resnet50\n",
        "from keras import optimizers\n",
        "import keras\n",
        "\n",
        "\n",
        "class MetricsCheckpoint(Callback):\n",
        "    \"\"\"Callback that saves metrics after each epoch\"\"\"\n",
        "    def __init__(self, savepath):\n",
        "        super(MetricsCheckpoint, self).__init__()\n",
        "        self.savepath = savepath\n",
        "        self.history = {}\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        np.save(self.savepath, self.history)\n",
        "\n",
        "\n",
        "pretrained_VGG16 = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(img_height, img_width, channels))\n",
        "\n",
        "# pretrained_resnet50 = resnet50(weights='imagenet',\n",
        "#                       include_top=False,\n",
        "#                       input_shape=(img_height, img_width, channels))\n",
        "\n",
        "def downStreamModel(train_generator, valid_generator, test_generator, pt_model, optimizer):\n",
        "    base_model = pt_model\n",
        "    x = base_model.output\n",
        "    x = Conv2D(256, kernel_size=(3, 3), padding='valid')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.75)(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    \n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    \n",
        "    # Train top layers only\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "    callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=10, verbose=1)]\n",
        "    model.summary()\n",
        "    \n",
        "    history = model.fit_generator(\n",
        "                train_generator,\n",
        "                steps_per_epoch=nb_train_samples / batch_size,\n",
        "                epochs=epochs,\n",
        "                validation_data=valid_generator,\n",
        "                validation_steps=nb_valid_samples / batch_size,\n",
        "                shuffle=True,\n",
        "                verbose=1,\n",
        "                callbacks=callbacks_list+[MetricsCheckpoint('logs')])\n",
        "    \n",
        "    score = model.evaluate_generator(test_generator, verbose=0, steps=nb_test_samples / batch_size,)\n",
        "    print('accuracy:', score[1])\n",
        "    # for generating confusion matrix and more statistics\n",
        "    # y_pred = model.predict_generator(test_generator)\n",
        "    # print(sklearn.metrics.classification_report(np.where()))\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cVkR8VIDerSV",
        "colab_type": "code",
        "outputId": "af225d0c-ee59-4697-d2ea-2dfbbe4c46ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2141
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer1 = keras.optimizers.Adam()\n",
        "optimizer2 = keras.optimizers.RMSprop(lr=0.0001/2.0)\n",
        "\n",
        "model = downStreamModel(train_generator, valid_generator, test_generator, pretrained_VGG16, optimizer1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 5, 5, 256)         1179904   \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 25604     \n",
            "=================================================================\n",
            "Total params: 15,920,196\n",
            "Trainable params: 1,205,508\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "63/62 [==============================] - 2678s 43s/step - loss: 1.1089 - acc: 0.6380 - val_loss: 0.2191 - val_acc: 0.9375\n",
            "Epoch 2/50\n",
            "63/62 [==============================] - 72s 1s/step - loss: 0.5535 - acc: 0.8062 - val_loss: 0.1902 - val_acc: 0.9062\n",
            "Epoch 3/50\n",
            "63/62 [==============================] - 72s 1s/step - loss: 0.4590 - acc: 0.8377 - val_loss: 0.2802 - val_acc: 0.8750\n",
            "Epoch 4/50\n",
            "63/62 [==============================] - 71s 1s/step - loss: 0.3819 - acc: 0.8615 - val_loss: 0.2422 - val_acc: 0.8750\n",
            "Epoch 5/50\n",
            "63/62 [==============================] - 71s 1s/step - loss: 0.3712 - acc: 0.8736 - val_loss: 0.1113 - val_acc: 0.9688\n",
            "Epoch 6/50\n",
            "63/62 [==============================] - 71s 1s/step - loss: 0.3780 - acc: 0.8735 - val_loss: 0.1258 - val_acc: 0.9375\n",
            "Epoch 7/50\n",
            "63/62 [==============================] - 71s 1s/step - loss: 0.3952 - acc: 0.8735 - val_loss: 0.2640 - val_acc: 0.8750\n",
            "Epoch 8/50\n",
            "63/62 [==============================] - 71s 1s/step - loss: 0.3545 - acc: 0.8817 - val_loss: 0.1065 - val_acc: 0.9062\n",
            "Epoch 9/50\n",
            "63/62 [==============================] - 71s 1s/step - loss: 0.3664 - acc: 0.8802 - val_loss: 0.2971 - val_acc: 0.8750\n",
            "Epoch 10/50\n",
            "63/62 [==============================] - 71s 1s/step - loss: 0.3201 - acc: 0.8979 - val_loss: 0.1121 - val_acc: 0.9375\n",
            "Epoch 11/50\n",
            "63/62 [==============================] - 71s 1s/step - loss: 0.3737 - acc: 0.8880 - val_loss: 0.1594 - val_acc: 0.9375\n",
            "Epoch 12/50\n",
            "63/62 [==============================] - 71s 1s/step - loss: 0.3365 - acc: 0.9007 - val_loss: 0.1512 - val_acc: 0.9375\n",
            "Epoch 13/50\n",
            "63/62 [==============================] - 71s 1s/step - loss: 0.2798 - acc: 0.9101 - val_loss: 0.1521 - val_acc: 0.9375\n",
            "Epoch 14/50\n",
            "63/62 [==============================] - 71s 1s/step - loss: 0.3362 - acc: 0.9040 - val_loss: 0.0846 - val_acc: 0.9688\n",
            "Epoch 15/50\n",
            "63/62 [==============================] - 71s 1s/step - loss: 0.3030 - acc: 0.9102 - val_loss: 0.3399 - val_acc: 0.8750\n",
            "Epoch 00015: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-653ff42fbd3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdownStreamModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_VGG16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-00a811320440>\u001b[0m in \u001b[0;36mdownStreamModel\u001b[0;34m(train_generator, valid_generator, test_generator, pt_model, optimizer)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 callbacks=callbacks_list+[MetricsCheckpoint('logs')])\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# for generating confusion matrix and more statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             raise ValueError('`steps=None` is only valid for a generator'\n\u001b[0m\u001b[1;32m    302\u001b[0m                              \u001b[0;34m' based on the `keras.utils.Sequence` class.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                              \u001b[0;34m' Please specify `steps` or use the'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: `steps=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps` or use the `keras.utils.Sequence` class."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "G1YfpWlQfhQW",
        "colab_type": "code",
        "outputId": "8ce2009f-f43a-4f0c-90b2-728259c1c579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "                train_generator,\n",
        "                steps_per_epoch=nb_train_samples / batch_size,\n",
        "                epochs=1,\n",
        "                validation_data=valid_generator,\n",
        "                validation_steps=nb_valid_samples / batch_size,\n",
        "                shuffle=True,\n",
        "                verbose=1,\n",
        "                callbacks=callbacks_list+[MetricsCheckpoint('logs')])\n",
        "\n",
        "score = model.evaluate_generator(test_generator, verbose=0, steps=1)\n",
        "print('accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-72ee8ce83f69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit_generator(\n\u001b[0m\u001b[1;32m      2\u001b[0m                 \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_train_samples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "un5BGWURuVW7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}