{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KaviMod4_tSNE_VGG16pretrain.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "9YsQvqoByt3g",
        "colab_type": "code",
        "outputId": "8556c4d3-d046-40b9-e9a5-54b3ae4b7a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "##### loading data #####\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YPs775E-fo0p",
        "colab_type": "code",
        "outputId": "09899f7a-a4d1-46cf-9fca-850c1e5f64a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# train_dir = \"/gdrive/My Drive/kaggle_dataset/train/\"\n",
        "# val_dir = \"/gdrive/My Drive/kaggle_dataset/val/\"\n",
        "# test_dir = \"/gdrive/My Drive/kaggle_dataset/test/\"\n",
        "\n",
        "train_dir = \"/gdrive/My Drive/trainProbMaps/\"\n",
        "val_dir = \"/gdrive/My Drive/valProbMaps/\"\n",
        "test_dir = \"/gdrive/My Drive/testProbMaps/\"\n",
        "\n",
        "\n",
        "img_width = 600\n",
        "img_height = 450\n",
        "\n",
        "# img_width = 512\n",
        "# img_height = 496\n",
        "\n",
        "batch_size = 5\n",
        "channels = 3\n",
        "epochs = 50\n",
        "nb_train_samples = 408\n",
        "nb_valid_samples = 149\n",
        "nb_test_samples = 192\n",
        "num_classes = 2\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)             \n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)    \n",
        "test_datagen = ImageDataGenerator(rescale=1./255) \n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, \n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True)   \n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True) #weight toward one class or another\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 408 images belonging to 2 classes.\n",
            "Found 149 images belonging to 2 classes.\n",
            "Found 192 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Stf1qT-VXxPT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Softmax, Flatten, Dense, BatchNormalization \n",
        "from keras.metrics import categorical_accuracy\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from PIL import Image\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "from keras import layers\n",
        "from keras.callbacks import TensorBoard, Callback\n",
        "from keras.applications import VGG16, resnet50\n",
        "from keras import optimizers\n",
        "import keras\n",
        "\n",
        "\n",
        "class MetricsCheckpoint(Callback):\n",
        "    \"\"\"Callback that saves metrics after each epoch\"\"\"\n",
        "    def __init__(self, savepath):\n",
        "        super(MetricsCheckpoint, self).__init__()\n",
        "        self.savepath = savepath\n",
        "        self.history = {}\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        np.save(self.savepath, self.history)\n",
        "\n",
        "\n",
        "pretrained_VGG16 = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(img_height, img_width, channels))\n",
        "\n",
        "# pretrained_resnet50 = resnet50(weights='imagenet',\n",
        "#                       include_top=False,\n",
        "#                       input_shape=(img_height, img_width, channels))\n",
        "\n",
        "# def downStreamModel(train_generator, valid_generator, test_generator, pt_model, optimizer):\n",
        "#     base_model = pt_model\n",
        "#     x = base_model.output\n",
        "#     convDS = Conv2D(256, kernel_size=(3, 3), padding='valid')(x)\n",
        "#     flatDS = Flatten()(x)\n",
        "#     dropOutDS = Dropout(0.75)(x)\n",
        "#     predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    \n",
        "#     model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    \n",
        "#     # Train top layers only\n",
        "#     for layer in base_model.layers:\n",
        "#         layer.trainable = False\n",
        "#     model.compile(loss='categorical_crossentropy',\n",
        "#                   optimizer=optimizer,\n",
        "#                   metrics=['accuracy'])\n",
        "#     callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=10, verbose=1)]\n",
        "#     model.summary()\n",
        "    \n",
        "#     history = model.fit_generator(\n",
        "#                 train_generator,\n",
        "#                 steps_per_epoch=nb_train_samples / batch_size,\n",
        "#                 epochs=epochs,\n",
        "#                 validation_data=valid_generator,\n",
        "#                 validation_steps=nb_valid_samples / batch_size,\n",
        "#                 shuffle=True,\n",
        "#                 verbose=1,\n",
        "#                 callbacks=callbacks_list+[MetricsCheckpoint('logs')])\n",
        "    \n",
        "#     score = model.evaluate_generator(test_generator, verbose=0, steps=nb_test_samples / batch_size,)\n",
        "#     print('accuracy:', score[1])\n",
        "#     # for generating confusion matrix and more statistics\n",
        "#     # y_pred = model.predict_generator(test_generator)\n",
        "#     # print(sklearn.metrics.classification_report(np.where()))\n",
        "#     return model\n",
        "\n",
        "def downStreamModel(train_generator, valid_generator, test_generator, pt_model, optimizer):\n",
        "    base_model = pt_model\n",
        "    x = base_model.output\n",
        "    convDS = Conv2D(256, kernel_size=(3, 3), padding='valid')(x)\n",
        "    flatDS = Flatten()(convDS)\n",
        "    dropOutDS = Dropout(0.75)(flatDS)\n",
        "    predictions = Dense(1, activation='softmax')(dropOutDS)\n",
        "    \n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    \n",
        "    # Train top layers only\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "    callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=10, verbose=1)]\n",
        "    model.summary()\n",
        "    \n",
        "    history = model.fit_generator(\n",
        "                train_generator,\n",
        "                steps_per_epoch=nb_train_samples / batch_size,\n",
        "                epochs=epochs,\n",
        "                validation_data=valid_generator,\n",
        "                validation_steps=nb_valid_samples / batch_size,\n",
        "                shuffle=True,\n",
        "                verbose=1,\n",
        "                callbacks=callbacks_list+[MetricsCheckpoint('logs')])\n",
        "    \n",
        "    convDenseModel =  Model(inputs=base_model.input, outputs=flatDS)\n",
        "    \n",
        "    predictionsConvDense = convDenseModel.predict_generator(test_generator, verbose=0, steps=nb_test_samples / batch_size)\n",
        "    \n",
        "    \n",
        "    score = model.evaluate_generator(test_generator, verbose=0, steps=nb_test_samples / batch_size,)\n",
        "    print('accuracy:', score[1])\n",
        "    # for generating confusionmatrix and more statistics\n",
        "    # y_pred = model.predict_generator(test_generator)\n",
        "    # print(sklearn.metrics.classification_report(np.where()))\n",
        "    return model, predictionsConvDense\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cVkR8VIDerSV",
        "colab_type": "code",
        "outputId": "301bd6e8-a71c-43aa-9e96-1267c156c1b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1479
        }
      },
      "cell_type": "code",
      "source": [
        "optimizer1 = keras.optimizers.Adam()\n",
        "optimizer2 = keras.optimizers.RMSprop(lr=0.0001/2.0)\n",
        "\n",
        "#convDenseModel =  Model(inputs=base_model.input, outputs=flatDS)\n",
        "\n",
        "#model = downStreamModel(train_generator, valid_generator, test_generator, pretrained_VGG16, optimizer1)\n",
        "model, predictionsConvDense = downStreamModel(train_generator, valid_generator, test_generator, pretrained_VGG16, optimizer1)\n",
        "\n",
        "print(predictionsConvDense.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 450, 600, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 450, 600, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 450, 600, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 225, 300, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 225, 300, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 225, 300, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 112, 150, 128)     0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 112, 150, 256)     295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 112, 150, 256)     590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 112, 150, 256)     590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 56, 75, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 56, 75, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 56, 75, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 56, 75, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 28, 37, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 28, 37, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 28, 37, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 28, 37, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 14, 18, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 16, 256)       1179904   \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 49152)             0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 49152)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 49153     \n",
            "=================================================================\n",
            "Total params: 15,943,745\n",
            "Trainable params: 1,229,057\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "82/81 [==============================] - 136s 2s/step - loss: 8.4895 - acc: 0.4675 - val_loss: 10.9136 - val_acc: 0.3154\n",
            "Epoch 2/50\n",
            "82/81 [==============================] - 49s 594ms/step - loss: 8.3084 - acc: 0.4789 - val_loss: 10.9136 - val_acc: 0.3154\n",
            "Epoch 3/50\n",
            "82/81 [==============================] - 49s 595ms/step - loss: 8.5151 - acc: 0.4659 - val_loss: 10.5926 - val_acc: 0.3356\n",
            "Epoch 4/50\n",
            "82/81 [==============================] - 49s 595ms/step - loss: 8.3994 - acc: 0.4731 - val_loss: 10.5926 - val_acc: 0.3356\n",
            "Epoch 5/50\n",
            "82/81 [==============================] - 49s 596ms/step - loss: 8.3472 - acc: 0.4764 - val_loss: 10.4856 - val_acc: 0.3423\n",
            "Epoch 6/50\n",
            "82/81 [==============================] - 49s 595ms/step - loss: 8.3084 - acc: 0.4789 - val_loss: 10.9136 - val_acc: 0.3154\n",
            "Epoch 7/50\n",
            "82/81 [==============================] - 49s 595ms/step - loss: 8.4639 - acc: 0.4691 - val_loss: 10.6996 - val_acc: 0.3289\n",
            "Epoch 8/50\n",
            "82/81 [==============================] - 49s 595ms/step - loss: 8.2828 - acc: 0.4805 - val_loss: 10.5926 - val_acc: 0.3356\n",
            "Epoch 9/50\n",
            "82/81 [==============================] - 49s 595ms/step - loss: 8.5417 - acc: 0.4642 - val_loss: 10.9136 - val_acc: 0.3154\n",
            "Epoch 10/50\n",
            "82/81 [==============================] - 49s 596ms/step - loss: 8.4250 - acc: 0.4715 - val_loss: 10.5926 - val_acc: 0.3356\n",
            "Epoch 11/50\n",
            "82/81 [==============================] - 49s 596ms/step - loss: 8.3216 - acc: 0.4780 - val_loss: 10.5926 - val_acc: 0.3356\n",
            "Epoch 12/50\n",
            "82/81 [==============================] - 49s 595ms/step - loss: 8.2951 - acc: 0.4797 - val_loss: 10.8066 - val_acc: 0.3221\n",
            "Epoch 13/50\n",
            "82/81 [==============================] - 49s 595ms/step - loss: 8.5284 - acc: 0.4650 - val_loss: 10.8066 - val_acc: 0.3221\n",
            "Epoch 14/50\n",
            "82/81 [==============================] - 49s 595ms/step - loss: 8.2951 - acc: 0.4797 - val_loss: 10.6996 - val_acc: 0.3289\n",
            "Epoch 15/50\n",
            "82/81 [==============================] - 49s 596ms/step - loss: 8.3605 - acc: 0.4756 - val_loss: 10.4856 - val_acc: 0.3423\n",
            "Epoch 00015: early stopping\n",
            "accuracy: 0.4791666666666667\n",
            "(192, 49152)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5DtPnp5fr-A9",
        "colab_type": "code",
        "outputId": "635a9abc-dfb5-434b-d2a2-52eec4bdba08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "print(predictionsConvDense.shape)\n",
        "\n",
        "#features = predictionsConvDense.predict()\n",
        "\n",
        "from google.colab import files\n",
        "# test_features = np.reshape(test_features, (192, 7*7*512))\n",
        "# print(test_features.shape)\n",
        "#np.savetxt('LabelsTest2.txt', test_labels)\n",
        "#files.download('LabelsTest2.txt')\n",
        "np.savetxt('VGG_RF_FeaturesTest2.txt', predictionsConvDense)\n",
        "files.download('VGG_RF_FeaturesTest2.txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(192, 49152)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Exception happened during processing of request from ('::ffff:127.0.0.1', 42490, 0, 0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
            "    self.process_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
            "    self.finish_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
            "    self.RequestHandlerClass(request, client_address, self)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
            "    self.handle()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n",
            "    self.handle_one_request()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n",
            "    method()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n",
            "    self.copyfile(f, self.wfile)\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n",
            "    shutil.copyfileobj(source, outputfile)\n",
            "  File \"/usr/lib/python3.6/shutil.py\", line 82, in copyfileobj\n",
            "    fdst.write(buf)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 800, in write\n",
            "    self._sock.sendall(b)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "----------------------------------------\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "yIwpQte_Nu_V",
        "colab_type": "code",
        "outputId": "7e6ced0d-0ad8-4116-b020-6f386122e55d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "def extract_features(dataset_type, sample_count):\n",
        "    features = np.zeros(shape=(sample_count, 12, 16, 64))\n",
        "    labels = np.zeros(shape=(sample_count))\n",
        "    i = 0\n",
        "    if dataset_type == \"train\":\n",
        "        for inputs_batch, labels_batch in train_generator:\n",
        "            features_batch = convDenseModel.predict(inputs_batch)\n",
        "            features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "            labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "            i += 1\n",
        "            if i * batch_size >= sample_count:\n",
        "                break   \n",
        "    elif dataset_type == \"valid\":\n",
        "        for inputs_batch, labels_batch in valid_generator:\n",
        "            features_batch = convDenseModel.predict(inputs_batch)\n",
        "            features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "            labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "            i += 1\n",
        "            if i * batch_size >= sample_count:\n",
        "                break\n",
        "    else:\n",
        "        for inputs_batch, labels_batch in test_generator:\n",
        "            features_batch = convDenseModel.predict(inputs_batch)\n",
        "            features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "            labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "            i += 1\n",
        "            if i * batch_size >= sample_count:\n",
        "                break\n",
        "    return features, labels\n",
        "\n",
        "train_features, train_labels = extract_features(\"train\", nb_train_samples)\n",
        "valid_features, valid_labels = extract_features(\"valid\", nb_valid_samples)\n",
        "test_features, test_labels = extract_features(\"test\", nb_test_samples)\n",
        "\n",
        "\n",
        "print(train_features.shape, train_labels.shape)\n",
        "print(valid_features.shape, valid_labels.shape)\n",
        "print(test_features.shape, test_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-f2a4ad803364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_train_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mvalid_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_valid_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_test_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-f2a4ad803364>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(dataset_type, sample_count)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdataset_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minputs_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mfeatures_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvDenseModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'convDenseModel' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "G1YfpWlQfhQW",
        "colab_type": "code",
        "outputId": "8ce2009f-f43a-4f0c-90b2-728259c1c579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(\n",
        "                train_generator,\n",
        "                steps_per_epoch=nb_train_samples / batch_size,\n",
        "                epochs=1,\n",
        "                validation_data=valid_generator,\n",
        "                validation_steps=nb_valid_samples / batch_size,\n",
        "                shuffle=True,\n",
        "                verbose=1,\n",
        "                callbacks=callbacks_list+[MetricsCheckpoint('logs')])\n",
        "\n",
        "score = model.evaluate_generator(test_generator, verbose=0, steps=1)\n",
        "print('accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-72ee8ce83f69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit_generator(\n\u001b[0m\u001b[1;32m      2\u001b[0m                 \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_train_samples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "un5BGWURuVW7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}