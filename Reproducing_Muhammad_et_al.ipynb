{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reproducing_Muhammad_et_al.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "5rilcimc5wRi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "58de88f9-a504-4670-eca5-27bce2cee20b"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IBSfXP7nTmHA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Data Preparation##"
      ]
    },
    {
      "metadata": {
        "id": "uAFrPctRGuTY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# EGD cell\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np \n",
        "\n",
        "# img_width = 475\n",
        "# img_height = 388\n",
        "img_width = 224\n",
        "img_height = 224\n",
        "batch_size = 1\n",
        "channels = 3\n",
        "\n",
        "#EGD data\n",
        "egd_dir = \"/gdrive/My Drive/EGD/\"\n",
        "\n",
        "egd_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "egd_generator = egd_datagen.flow_from_directory(\n",
        "    egd_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True)\n",
        "\n",
        "features = np.zeros(shape=(102, img_height, img_width, 3))\n",
        "labels = np.zeros(shape=(102))\n",
        "i = 0\n",
        "\n",
        "for inputs_batch, labels_batch in egd_generator:\n",
        "    features[i * batch_size : (i + 1) * batch_size] = inputs_batch\n",
        "    labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "    i += 1\n",
        "    if i * batch_size >= 102:\n",
        "        break   \n",
        "        \n",
        "print(features.shape, labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xv8KU7pUK433",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
        "\n",
        "# if Alexnet\n",
        "# X_train = np.rollaxis(X_train, 3, 1)  \n",
        "# X_test = np.rollaxis(X_test, 3, 1)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jXLvvnfpTcNZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##VGG16 pretrained##"
      ]
    },
    {
      "metadata": {
        "id": "ijUX56CXL82a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        },
        "outputId": "8a57dd31-6018-432d-80d0-3d6bd4677185"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Softmax, Flatten, Dense, BatchNormalization \n",
        "from keras.metrics import categorical_accuracy\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from PIL import Image\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "from keras import layers\n",
        "from keras.callbacks import TensorBoard, Callback\n",
        "from keras.applications import VGG16, resnet50\n",
        "from keras import optimizers\n",
        "import keras\n",
        "\n",
        "\n",
        "class MetricsCheckpoint(Callback):\n",
        "    \"\"\"Callback that saves metrics after each epoch\"\"\"\n",
        "    def __init__(self, savepath):\n",
        "        super(MetricsCheckpoint, self).__init__()\n",
        "        self.savepath = savepath\n",
        "        self.history = {}\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        np.save(self.savepath, self.history)\n",
        "\n",
        "\n",
        "base_model = VGG16(weights='imagenet',\n",
        "                  include_top=True,\n",
        "                  input_shape=(img_height, img_width, channels))\n",
        "\n",
        "base_model.summary()\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=base_model.get_layer('predictions').output)\n",
        "\n",
        "X_train_1k_features = model.predict(X_train)\n",
        "X_test_1k_features =  model.predict(X_test)\n",
        "print(X_train_1k_features.shape)\n",
        "print(X_test_1k_features.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(81, 1000)\n",
            "(21, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1w-0SpE3O2uc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "283702b3-f731-44b0-89db-9a154eda504e"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=12, random_state=0, bootstrap=True)\n",
        "clf.fit(X_train_1k_features, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test_1k_features) \n",
        "aroc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "test_score = clf.score(X_test_1k_features, y_test)\n",
        "\n",
        "print(\"test precision:\", test_score)\n",
        "print(\"test AROC:\", aroc)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test precision: 0.8571428571428571\n",
            "test AROC: 0.8545454545454546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7L5XyA0xTfm4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##AlexNet pretrained##"
      ]
    },
    {
      "metadata": {
        "id": "ROzjVUapbvPm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "ab3fce7f-3a04-4380-b871-357392738afe"
      },
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/heuritech/convnets-keras.git\n",
        "# !cd convnets-keras\n",
        "# !python setup.py install\n",
        "! ls convnets-keras/\n",
        "! cd convnets-keras;python setup.py install\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convnetskeras  examples  LICENSE.txt  README.md  setup.py\n",
            "running install\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/convnetskeras\n",
            "copying convnetskeras/__init__.py -> build/lib/convnetskeras\n",
            "copying convnetskeras/imagenet_tool.py -> build/lib/convnetskeras\n",
            "copying convnetskeras/customlayers.py -> build/lib/convnetskeras\n",
            "copying convnetskeras/convnets.py -> build/lib/convnetskeras\n",
            "creating build/lib/convnetskeras/data\n",
            "copying convnetskeras/data/meta_clsloc.mat -> build/lib/convnetskeras/data\n",
            "running install_lib\n",
            "creating /usr/local/lib/python3.6/dist-packages/convnetskeras\n",
            "copying build/lib/convnetskeras/__init__.py -> /usr/local/lib/python3.6/dist-packages/convnetskeras\n",
            "creating /usr/local/lib/python3.6/dist-packages/convnetskeras/data\n",
            "copying build/lib/convnetskeras/data/meta_clsloc.mat -> /usr/local/lib/python3.6/dist-packages/convnetskeras/data\n",
            "copying build/lib/convnetskeras/imagenet_tool.py -> /usr/local/lib/python3.6/dist-packages/convnetskeras\n",
            "copying build/lib/convnetskeras/customlayers.py -> /usr/local/lib/python3.6/dist-packages/convnetskeras\n",
            "copying build/lib/convnetskeras/convnets.py -> /usr/local/lib/python3.6/dist-packages/convnetskeras\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/convnetskeras/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/convnetskeras/imagenet_tool.py to imagenet_tool.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/convnetskeras/customlayers.py to customlayers.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/convnetskeras/convnets.py to convnets.cpython-36.pyc\n",
            "running install_egg_info\n",
            "Writing /usr/local/lib/python3.6/dist-packages/convnetskeras-0.1.egg-info\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lb_edgpQcAH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "8a858811-08e9-4380-eabe-41e1915f61db"
      },
      "cell_type": "code",
      "source": [
        "from convnetskeras import convnets\n",
        "model = convnet('alexnet',weights_path=\"alexnet_weights.h5\", heatmap=False)\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-a42c968995d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconvnetskeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvnets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'alexnet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"alexnet_weights.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheatmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/convnetskeras/convnets.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# -*- coding: utf-8 -*-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconvnetskeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustomlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrosschannelnormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconvnetskeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustomlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSoftmax4D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconvnetskeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustomlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msplittensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/convnetskeras/customlayers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Merge'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ZFwYpCzlSh4_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "outputId": "f452deee-6a61-44bd-e4a3-7564137f9189"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "# from keras.layers import concaten\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.convolutional import ZeroPadding2D\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras import backend as K\n",
        "from keras.engine import Layer\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.core import Lambda\n",
        "from keras.layers import concatenate\n",
        "\n",
        "def splittensor(axis=1, ratio_split=1, id_split=0, **kwargs):\n",
        "    def f(X):\n",
        "        div = X.shape[axis] // ratio_split\n",
        "\n",
        "        if axis == 0:\n",
        "            output = X[id_split * div:(id_split + 1) * div, :, :, :]\n",
        "        elif axis == 1:\n",
        "            output = X[:, id_split * div:(id_split + 1) * div, :, :]\n",
        "        elif axis == 2:\n",
        "            output = X[:, :, id_split * div:(id_split + 1) * div, :]\n",
        "        elif axis == 3:\n",
        "            output = X[:, :, :, id_split * div:(id_split + 1) * div]\n",
        "        else:\n",
        "            raise ValueError('This axis is not possible')\n",
        "\n",
        "        return output\n",
        "\n",
        "    def g(input_shape):\n",
        "        output_shape = list(input_shape)\n",
        "        output_shape[axis] = output_shape[axis] // ratio_split\n",
        "        return tuple(output_shape)\n",
        "\n",
        "    return Lambda(f, output_shape=lambda input_shape: g(input_shape), **kwargs)\n",
        "\n",
        "def crosschannelnormalization(alpha=1e-4, k=2, beta=0.75, n=5, **kwargs):\n",
        "    \"\"\"\n",
        "    This is the function used for cross channel normalization in the original\n",
        "    Alexnet\n",
        "    \"\"\"\n",
        "\n",
        "    def f(X):\n",
        "        b, ch, r, c = X.shape\n",
        "        half = n // 2\n",
        "        square = K.square(X)\n",
        "        extra_channels = K.spatial_2d_padding(K.permute_dimensions(square, (0, 2, 3, 1))\n",
        "                                              , (0, half))\n",
        "        extra_channels = K.permute_dimensions(extra_channels, (0, 3, 1, 2))\n",
        "        scale = k\n",
        "        for i in range(n):\n",
        "            scale += alpha * extra_channels[:, i:i + ch, :, :]\n",
        "        scale = scale ** beta\n",
        "        return X / scale\n",
        "\n",
        "    return Lambda(f, output_shape=lambda input_shape: input_shape, **kwargs)\n",
        "\n",
        "\n",
        "def AlexNet(weights_path=None):\n",
        "    \n",
        "    inputs = Input(shape=(227, 227, 3))\n",
        "    conv_1 = Convolution2D(96, 11, 11, subsample=(4, 4), activation='relu',name='conv_1')(inputs)\n",
        "\n",
        "    conv_2 = MaxPooling2D((3, 3), strides=(2, 2))(conv_1)\n",
        "    conv_2 = crosschannelnormalization(name='convpool_1')(conv_2)\n",
        "    conv_2 = ZeroPadding2D((2, 2))(conv_2)\n",
        "    conv_2 = concatenate([Convolution2D(128, 5, 5, activation='relu', name='conv_2_' + str(i + 1))(splittensor(ratio_split=2, id_split=i)(conv_2)) for i in range(2)], mode='concat', concat_axis=1, name='conv_2')\n",
        "\n",
        "    conv_3 = MaxPooling2D((3, 3), strides=(2, 2))(conv_2)\n",
        "    conv_3 = crosschannelnormalization()(conv_3)\n",
        "    conv_3 = ZeroPadding2D((1, 1))(conv_3)\n",
        "    conv_3 = Convolution2D(384, 3, 3, activation='relu', name='conv_3')(conv_3)\n",
        "\n",
        "    conv_4 = ZeroPadding2D((1, 1))(conv_3)\n",
        "    conv_4 = concatenate([Convolution2D(192, 3, 3, activation='relu', name='conv_4_' + str(i + 1))(splittensor(ratio_split=2, id_split=i)(conv_4)) for i in range(2)], mode='concat', concat_axis=1, name='conv_4')\n",
        "\n",
        "    conv_5 = ZeroPadding2D((1, 1))(conv_4)\n",
        "    conv_5 = concatenate([Convolution2D(128, 3, 3, activation='relu', name='conv_5_' + str(i + 1))(splittensor(ratio_split=2, id_split=i)(conv_5)) for i in range(2)], mode='concat', concat_axis=1, name='conv_5')\n",
        "\n",
        "    dense_1 = MaxPooling2D((3, 3), strides=(2, 2), name='convpool_5')(conv_5)\n",
        "\n",
        "    dense_1 = Flatten(name='flatten')(dense_1)\n",
        "    dense_1 = Dense(4096, activation='relu', name='dense_1')(dense_1)\n",
        "    dense_2 = Dropout(0.5)(dense_1)\n",
        "    dense_2 = Dense(4096, activation='relu', name='dense_2')(dense_2)\n",
        "    dense_3 = Dropout(0.5)(dense_2)\n",
        "    dense_3 = Dense(1000, name='dense_3')(dense_3)\n",
        "    prediction = Activation('softmax', name='softmax')(dense_3)\n",
        "    model = Model(input=inputs, output=prediction)\n",
        "\n",
        "    if weights_path:\n",
        "        model.load_weights(weights_path)\n",
        "\n",
        "    return model\n",
        "\n",
        "alex_weight_path = 'alexnet_weights.h5'\n",
        "\n",
        "base_model = AlexNet(alex_weight_path)\n",
        "base_model.summary()\n",
        "\n",
        "# model = Model(inputs=base_model.input, outputs=base_model.get_layer('predictions').output)\n",
        "# X_train_1k_features = model.predict(X_train)\n",
        "# X_test_1k_features =  model.predict(X_test)\n",
        "# print(X_train_1k_features.shape)\n",
        "# print(X_test_1k_features.shape)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (11, 11), activation=\"relu\", name=\"conv_1\", strides=(4, 4))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-20f7b056ed7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0malex_weight_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'alexnet_weights.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlexNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malex_weight_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-20f7b056ed7f>\u001b[0m in \u001b[0;36mAlexNet\u001b[0;34m(weights_path)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mconv_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mconv_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrosschannelnormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'convpool_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mconv_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mconv_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv_2_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplittensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'concat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv_2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-20f7b056ed7f>\u001b[0m in \u001b[0;36mf\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0msquare\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         extra_channels = K.spatial_2d_padding(K.permute_dimensions(square, (0, 2, 3, 1))\n\u001b[0;32m---> 55\u001b[0;31m                                               , (0, half))\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mextra_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mspatial_2d_padding\u001b[0;34m(x, padding, data_format)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \"\"\"\n\u001b[1;32m   2277\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2278\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2279\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2280\u001b[0m     \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "QUizD3aiVYbS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=12, random_state=0, bootstrap=True)\n",
        "clf.fit(X_train_1k_features, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test_1k_features) \n",
        "aroc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "test_score = clf.score(X_test_1k_features, y_test)\n",
        "\n",
        "print(\"test precision:\", test_score)\n",
        "print(\"test AROC:\", aroc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}