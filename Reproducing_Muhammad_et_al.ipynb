{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reproducing_Muhammad_et_al.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "5rilcimc5wRi",
        "colab_type": "code",
        "outputId": "4d6a0aab-0a8c-44e8-cc06-de709faf8071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IBSfXP7nTmHA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Data Preparation##"
      ]
    },
    {
      "metadata": {
        "id": "uAFrPctRGuTY",
        "colab_type": "code",
        "outputId": "d4cc23ea-badb-4038-b93c-833d1f6809a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "# EGD cell\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np \n",
        "\n",
        "# img_width = 475\n",
        "# img_height = 388\n",
        "img_width = 224\n",
        "img_height = 224\n",
        "batch_size = 1\n",
        "channels = 3\n",
        "\n",
        "#EGD data\n",
        "egd_dir = \"/gdrive/My Drive/EGD/\"\n",
        "\n",
        "egd_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "egd_generator = egd_datagen.flow_from_directory(\n",
        "    egd_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True)\n",
        "\n",
        "features = np.zeros(shape=(102, img_height, img_width, 3))\n",
        "labels = np.zeros(shape=(102))\n",
        "i = 0\n",
        "\n",
        "for inputs_batch, labels_batch in egd_generator:\n",
        "    features[i * batch_size : (i + 1) * batch_size] = inputs_batch\n",
        "    labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "    i += 1\n",
        "    if i * batch_size >= 102:\n",
        "        break   \n",
        "        \n",
        "print(features.shape, labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 102 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:2274: DecompressionBombWarning: Image size (171407884 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  DecompressionBombWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(102, 224, 224, 3) (102,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xv8KU7pUK433",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
        "\n",
        "# if Alexnet\n",
        "# X_train = np.rollaxis(X_train, 3, 1)  \n",
        "# X_test = np.rollaxis(X_test, 3, 1)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jXLvvnfpTcNZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##VGG16 pretrained##"
      ]
    },
    {
      "metadata": {
        "id": "ijUX56CXL82a",
        "colab_type": "code",
        "outputId": "9b6b04d4-d2ee-4fcd-9e75-7e34f1f218c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Softmax, Flatten, Dense, BatchNormalization \n",
        "from keras.metrics import categorical_accuracy\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from PIL import Image\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "from keras import layers\n",
        "from keras.callbacks import TensorBoard, Callback\n",
        "from keras.applications import VGG16, resnet50\n",
        "from keras import optimizers\n",
        "import keras\n",
        "\n",
        "\n",
        "class MetricsCheckpoint(Callback):\n",
        "    \"\"\"Callback that saves metrics after each epoch\"\"\"\n",
        "    def __init__(self, savepath):\n",
        "        super(MetricsCheckpoint, self).__init__()\n",
        "        self.savepath = savepath\n",
        "        self.history = {}\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        np.save(self.savepath, self.history)\n",
        "\n",
        "\n",
        "base_model = VGG16(weights='imagenet',\n",
        "                  include_top=True,\n",
        "                  input_shape=(img_height, img_width, channels))\n",
        "\n",
        "# base_model.summary()\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=base_model.get_layer('predictions').output)\n",
        "\n",
        "# X_train_1k_features = model.predict(X_train)\n",
        "# X_test_1k_features =  model.predict(X_test)\n",
        "# print(X_train_1k_features.shape)\n",
        "# print(X_test_1k_features.shape)\n",
        "features_1k = model.predict(features)\n",
        "print(features_1k.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(102, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U4hDfslfTXeq",
        "colab_type": "code",
        "outputId": "9130a733-886d-435b-c341-0c2fc1c0ee54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "kf = KFold(n_splits=10)\n",
        "kf.get_n_splits(features_1k)\n",
        "\n",
        "score_list = []\n",
        "auc_list = []\n",
        "\n",
        "for train_index, val_index in kf.split(features_1k):\n",
        "    clf = RandomForestClassifier(n_estimators=100, max_depth=12, random_state=0, bootstrap=True)\n",
        "    clf.fit(features_1k[train_index], labels[train_index])\n",
        "    valid_prediction = clf.predict(features_1k[val_index])\n",
        "    valid_score = clf.score(features_1k[val_index], labels[val_index])\n",
        "#     fpr, tpr, thresholds = metrics.roc_curve(labels[val_index], valid_prediction, pos_label=1)\n",
        "#     valid_auc = metrics.auc(fpr, tpr)\n",
        "    valid_auc = roc_auc_score(labels[val_index], valid_prediction)\n",
        "    score_list.append(valid_score)\n",
        "    auc_list.append(valid_auc)\n",
        "    \n",
        "print(\"mean score is: {}\".format(np.mean(score_list)))\n",
        "print(\"mean AUC is: {}\".format(np.mean(auc_list)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean score is: 0.8718181818181818\n",
            "mean AUC is: 0.8685714285714287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7L5XyA0xTfm4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##AlexNet pretrained##"
      ]
    },
    {
      "metadata": {
        "id": "ROzjVUapbvPm",
        "colab_type": "code",
        "outputId": "ab3fce7f-3a04-4380-b871-357392738afe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/heuritech/convnets-keras.git\n",
        "# !cd convnets-keras\n",
        "# !python setup.py install\n",
        "! ls convnets-keras/\n",
        "! cd convnets-keras;python setup.py install\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convnetskeras  examples  LICENSE.txt  README.md  setup.py\n",
            "running install\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/convnetskeras\n",
            "copying convnetskeras/__init__.py -> build/lib/convnetskeras\n",
            "copying convnetskeras/imagenet_tool.py -> build/lib/convnetskeras\n",
            "copying convnetskeras/customlayers.py -> build/lib/convnetskeras\n",
            "copying convnetskeras/convnets.py -> build/lib/convnetskeras\n",
            "creating build/lib/convnetskeras/data\n",
            "copying convnetskeras/data/meta_clsloc.mat -> build/lib/convnetskeras/data\n",
            "running install_lib\n",
            "creating /usr/local/lib/python3.6/dist-packages/convnetskeras\n",
            "copying build/lib/convnetskeras/__init__.py -> /usr/local/lib/python3.6/dist-packages/convnetskeras\n",
            "creating /usr/local/lib/python3.6/dist-packages/convnetskeras/data\n",
            "copying build/lib/convnetskeras/data/meta_clsloc.mat -> /usr/local/lib/python3.6/dist-packages/convnetskeras/data\n",
            "copying build/lib/convnetskeras/imagenet_tool.py -> /usr/local/lib/python3.6/dist-packages/convnetskeras\n",
            "copying build/lib/convnetskeras/customlayers.py -> /usr/local/lib/python3.6/dist-packages/convnetskeras\n",
            "copying build/lib/convnetskeras/convnets.py -> /usr/local/lib/python3.6/dist-packages/convnetskeras\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/convnetskeras/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/convnetskeras/imagenet_tool.py to imagenet_tool.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/convnetskeras/customlayers.py to customlayers.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/convnetskeras/convnets.py to convnets.cpython-36.pyc\n",
            "running install_egg_info\n",
            "Writing /usr/local/lib/python3.6/dist-packages/convnetskeras-0.1.egg-info\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lb_edgpQcAH_",
        "colab_type": "code",
        "outputId": "8a858811-08e9-4380-eabe-41e1915f61db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "cell_type": "code",
      "source": [
        "from convnetskeras import convnets\n",
        "model = convnet('alexnet',weights_path=\"alexnet_weights.h5\", heatmap=False)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-a42c968995d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconvnetskeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvnets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'alexnet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"alexnet_weights.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheatmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/convnetskeras/convnets.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# -*- coding: utf-8 -*-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconvnetskeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustomlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrosschannelnormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconvnetskeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustomlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSoftmax4D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconvnetskeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustomlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msplittensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/convnetskeras/customlayers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Merge'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ZFwYpCzlSh4_",
        "colab_type": "code",
        "outputId": "f452deee-6a61-44bd-e4a3-7564137f9189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "# from keras.layers import concaten\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.convolutional import ZeroPadding2D\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras import backend as K\n",
        "from keras.engine import Layer\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.core import Lambda\n",
        "from keras.layers import concatenate\n",
        "\n",
        "def splittensor(axis=1, ratio_split=1, id_split=0, **kwargs):\n",
        "    def f(X):\n",
        "        div = X.shape[axis] // ratio_split\n",
        "\n",
        "        if axis == 0:\n",
        "            output = X[id_split * div:(id_split + 1) * div, :, :, :]\n",
        "        elif axis == 1:\n",
        "            output = X[:, id_split * div:(id_split + 1) * div, :, :]\n",
        "        elif axis == 2:\n",
        "            output = X[:, :, id_split * div:(id_split + 1) * div, :]\n",
        "        elif axis == 3:\n",
        "            output = X[:, :, :, id_split * div:(id_split + 1) * div]\n",
        "        else:\n",
        "            raise ValueError('This axis is not possible')\n",
        "\n",
        "        return output\n",
        "\n",
        "    def g(input_shape):\n",
        "        output_shape = list(input_shape)\n",
        "        output_shape[axis] = output_shape[axis] // ratio_split\n",
        "        return tuple(output_shape)\n",
        "\n",
        "    return Lambda(f, output_shape=lambda input_shape: g(input_shape), **kwargs)\n",
        "\n",
        "def crosschannelnormalization(alpha=1e-4, k=2, beta=0.75, n=5, **kwargs):\n",
        "    \"\"\"\n",
        "    This is the function used for cross channel normalization in the original\n",
        "    Alexnet\n",
        "    \"\"\"\n",
        "\n",
        "    def f(X):\n",
        "        b, ch, r, c = X.shape\n",
        "        half = n // 2\n",
        "        square = K.square(X)\n",
        "        extra_channels = K.spatial_2d_padding(K.permute_dimensions(square, (0, 2, 3, 1))\n",
        "                                              , (0, half))\n",
        "        extra_channels = K.permute_dimensions(extra_channels, (0, 3, 1, 2))\n",
        "        scale = k\n",
        "        for i in range(n):\n",
        "            scale += alpha * extra_channels[:, i:i + ch, :, :]\n",
        "        scale = scale ** beta\n",
        "        return X / scale\n",
        "\n",
        "    return Lambda(f, output_shape=lambda input_shape: input_shape, **kwargs)\n",
        "\n",
        "\n",
        "def AlexNet(weights_path=None):\n",
        "    \n",
        "    inputs = Input(shape=(227, 227, 3))\n",
        "    conv_1 = Convolution2D(96, 11, 11, subsample=(4, 4), activation='relu',name='conv_1')(inputs)\n",
        "\n",
        "    conv_2 = MaxPooling2D((3, 3), strides=(2, 2))(conv_1)\n",
        "    conv_2 = crosschannelnormalization(name='convpool_1')(conv_2)\n",
        "    conv_2 = ZeroPadding2D((2, 2))(conv_2)\n",
        "    conv_2 = concatenate([Convolution2D(128, 5, 5, activation='relu', name='conv_2_' + str(i + 1))(splittensor(ratio_split=2, id_split=i)(conv_2)) for i in range(2)], mode='concat', concat_axis=1, name='conv_2')\n",
        "\n",
        "    conv_3 = MaxPooling2D((3, 3), strides=(2, 2))(conv_2)\n",
        "    conv_3 = crosschannelnormalization()(conv_3)\n",
        "    conv_3 = ZeroPadding2D((1, 1))(conv_3)\n",
        "    conv_3 = Convolution2D(384, 3, 3, activation='relu', name='conv_3')(conv_3)\n",
        "\n",
        "    conv_4 = ZeroPadding2D((1, 1))(conv_3)\n",
        "    conv_4 = concatenate([Convolution2D(192, 3, 3, activation='relu', name='conv_4_' + str(i + 1))(splittensor(ratio_split=2, id_split=i)(conv_4)) for i in range(2)], mode='concat', concat_axis=1, name='conv_4')\n",
        "\n",
        "    conv_5 = ZeroPadding2D((1, 1))(conv_4)\n",
        "    conv_5 = concatenate([Convolution2D(128, 3, 3, activation='relu', name='conv_5_' + str(i + 1))(splittensor(ratio_split=2, id_split=i)(conv_5)) for i in range(2)], mode='concat', concat_axis=1, name='conv_5')\n",
        "\n",
        "    dense_1 = MaxPooling2D((3, 3), strides=(2, 2), name='convpool_5')(conv_5)\n",
        "\n",
        "    dense_1 = Flatten(name='flatten')(dense_1)\n",
        "    dense_1 = Dense(4096, activation='relu', name='dense_1')(dense_1)\n",
        "    dense_2 = Dropout(0.5)(dense_1)\n",
        "    dense_2 = Dense(4096, activation='relu', name='dense_2')(dense_2)\n",
        "    dense_3 = Dropout(0.5)(dense_2)\n",
        "    dense_3 = Dense(1000, name='dense_3')(dense_3)\n",
        "    prediction = Activation('softmax', name='softmax')(dense_3)\n",
        "    model = Model(input=inputs, output=prediction)\n",
        "\n",
        "    if weights_path:\n",
        "        model.load_weights(weights_path)\n",
        "\n",
        "    return model\n",
        "\n",
        "alex_weight_path = 'alexnet_weights.h5'\n",
        "\n",
        "base_model = AlexNet(alex_weight_path)\n",
        "base_model.summary()\n",
        "\n",
        "# model = Model(inputs=base_model.input, outputs=base_model.get_layer('predictions').output)\n",
        "# X_train_1k_features = model.predict(X_train)\n",
        "# X_test_1k_features =  model.predict(X_test)\n",
        "# print(X_train_1k_features.shape)\n",
        "# print(X_test_1k_features.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (11, 11), activation=\"relu\", name=\"conv_1\", strides=(4, 4))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-20f7b056ed7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0malex_weight_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'alexnet_weights.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlexNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malex_weight_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-20f7b056ed7f>\u001b[0m in \u001b[0;36mAlexNet\u001b[0;34m(weights_path)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mconv_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mconv_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrosschannelnormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'convpool_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mconv_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mconv_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv_2_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplittensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'concat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv_2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-20f7b056ed7f>\u001b[0m in \u001b[0;36mf\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0msquare\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         extra_channels = K.spatial_2d_padding(K.permute_dimensions(square, (0, 2, 3, 1))\n\u001b[0;32m---> 55\u001b[0;31m                                               , (0, half))\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mextra_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mspatial_2d_padding\u001b[0;34m(x, padding, data_format)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \"\"\"\n\u001b[1;32m   2277\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2278\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2279\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2280\u001b[0m     \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "QUizD3aiVYbS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=12, random_state=0, bootstrap=True)\n",
        "clf.fit(X_train_1k_features, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test_1k_features) \n",
        "aroc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "test_score = clf.score(X_test_1k_features, y_test)\n",
        "\n",
        "print(\"test precision:\", test_score)\n",
        "print(\"test AROC:\", aroc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}