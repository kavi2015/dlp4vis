{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorchDataLoaderOCT.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "102x9yji2cbw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "fdcdca7f-e635-4f39-f593-30ae3551eb17"
      },
      "cell_type": "code",
      "source": [
        "#Excerpt from COMS 4995 Assignment #1\n",
        "#Part 2: CNN Using Pytorch\n",
        "#Kaveri Thakoor, Linyong Nan\n",
        "#Colab Notebook URL: \n",
        "#https://colab.research.google.com/drive/1Y89IVS00CxRuRQZ6PG4YqZlNfbafTNNY\n",
        "\n",
        "#Code to import correct version of pytorch\n",
        "!cat /etc/*-release\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DISTRIB_ID=Ubuntu\n",
            "DISTRIB_RELEASE=18.04\n",
            "DISTRIB_CODENAME=bionic\n",
            "DISTRIB_DESCRIPTION=\"Ubuntu 18.04.1 LTS\"\n",
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"18.04.1 LTS (Bionic Beaver)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 18.04.1 LTS\"\n",
            "VERSION_ID=\"18.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=bionic\n",
            "UBUNTU_CODENAME=bionic\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xZ2lzfhP2i0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "b82c84e7-5cf5-4781-9d91-024ec6d20ed8"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print (sys.version)\n",
        "\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available()) "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.6 (default, Sep 12 2018, 18:26:19) \n",
            "[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]]\n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5c060000 @  0x7f5fecb752a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n",
            "0.4.0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Us0gneu023OA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1053
        },
        "outputId": "70cf9b68-b7c3-4047-a741-875ce11d9cfe"
      },
      "cell_type": "code",
      "source": [
        "#!easy_install-2.7 --user PIL\n",
        "!pip install --no-cache-dir -I pillow\n",
        "!pip3 install imageio\n",
        "\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "from torch.utils import data\n",
        "# path1 is the path to the folder of images with disease \n",
        "# path2 is the path to the folder of images without disease \n",
        "path1 = \"/gdrive/My Drive/new_dataset/trainProbMaps/patients/*\"\n",
        "path2 = \"/gdrive/My Drive/new_dataset/trainProb/controls/*\"\n",
        "path3 = \"/gdrive/My Drive/new_dataset/valProbMaps/patients/*\"\n",
        "path4 = \"/gdrive/My Drive/new_dataset/valProbMaps/controls/*\"\n",
        "\n",
        "class data_reader(data.Dataset):\n",
        "    def __init__(self, mode):\n",
        "        self.mode = mode\n",
        "        self.train_list = []\n",
        "        self.val_list = []\n",
        "        if self.mode == 'train':\n",
        "            files1 = glob.glob(path1)\n",
        "            files2 = glob.glob(path2)\n",
        "            for i in files1:\n",
        "                self.train_list.append((i,0))\n",
        "            for i in files2:\n",
        "                self.train_list.append((i,1))\n",
        "            print (len(self.train_list))\n",
        "        elif self.mode == 'val':\n",
        "            files1 = glob.glob(path3)\n",
        "            files2 = glob.glob(path4)                  \n",
        "            for i in files1:\n",
        "                self.val_list.append((i,0))\n",
        "            for i in files2:\n",
        "                self.val_list.append((i,1)) \n",
        "            print (len(self.val_list))\n",
        "        else:\n",
        "            print('mode can only be train or val')\n",
        "        \n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        #print ('here')\n",
        "         #self.mode = mode\n",
        "        if self.mode == 'train':\n",
        "            filepath = self.train_list[index][0]\n",
        "            label = self.train_list[index][1]\n",
        "            img = imageio.imread(filepath)    \n",
        "            img = img.transpose(2,0,1)\n",
        "        elif self.mode == 'val':\n",
        "            filepath = self.val_list[index][0]\n",
        "            label = self.val_list[index][1]\n",
        "            img = imageio.imread(filepath) \n",
        "            img = img.transpose(2,0,1)\n",
        "        #print (img.shape)\n",
        "        return np.array(img), label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.train_list)\n",
        "        \n",
        "#     def augment(self,I):\n",
        "#       # write code to augment image here - random crops, random flips etc\n",
        "#       # if you dont want to augment images, leave this as it is\n",
        "#       pass\n",
        "#       return I\n",
        "\n",
        "# to use the dataloader\n",
        "\n",
        "batch_size = 25\n",
        "\n",
        "train_reader = data_reader(mode='train')\n",
        "#val_reader = data_reader(mode='val')\n",
        "#epochs = 15\n",
        "\n",
        "for epoch in range(15):\n",
        "    train_dataloader = data.DataLoader(train_reader,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=False,\n",
        "                num_workers=1,\n",
        "                drop_last=False)\n",
        "    \n",
        "# for epoch in range(15):\n",
        "#     val_dataloader = data.DataLoader(val_reader,\n",
        "#             batch_size=batch_size,\n",
        "#             shuffle=False,\n",
        "#             num_workers=1,\n",
        "#             drop_last=False)\n",
        "\n",
        "\n",
        "for images, labels in train_dataloader:\n",
        "    print (images.size())\n",
        "# for images, labels in val_dataloader:\n",
        "#     print(images.size())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pillow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 20.6MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "Successfully installed pillow-5.3.0\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.14.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (5.3.0)\n",
            "195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6f9b1731a8b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# for images, labels in val_dataloader:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-8-6f9b1731a8b9>\", line 55, in __getitem__\n    img = imageio.imread(filepath)\n  File \"/usr/local/lib/python3.6/dist-packages/imageio/core/functions.py\", line 221, in imread\n    reader = read(uri, format, \"i\", **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/imageio/core/functions.py\", line 136, in get_reader\n    format = formats.search_read_format(request)\n  File \"/usr/local/lib/python3.6/dist-packages/imageio/core/format.py\", line 687, in search_read_format\n    if format.can_read(request):\n  File \"/usr/local/lib/python3.6/dist-packages/imageio/core/format.py\", line 195, in can_read\n    return self._can_read(request)\n  File \"/usr/local/lib/python3.6/dist-packages/imageio/plugins/pillow.py\", line 99, in _can_read\n    Image = self._init_pillow()\n  File \"/usr/local/lib/python3.6/dist-packages/imageio/plugins/pillow.py\", line 93, in _init_pillow\n    Image.preinit()\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 370, in preinit\n    def preinit():\n  File \"/usr/local/lib/python3.6/dist-packages/PIL/PpmImagePlugin.py\", line 158, in <module>\n    Image.register_extensions(PpmImageFile.format, [\".pbm\", \".pgm\", \".ppm\"])\nAttributeError: module 'PIL.Image' has no attribute 'register_extensions'\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "YOcC9NYD243O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#First Model Variation: ConvNetModelBest\n",
        "class ConvNetModelBest(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNetModelBest, self).__init__()\n",
        "        # input is 32x32\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        # feature map size is 16*16 by pooling\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        # feature map size is 8*8 by pooling\n",
        "        #Adding third conv layer\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        # feature map size is 4*4 by pooling\n",
        "        self.fc1 = nn.Linear(128*4*4, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x = (-1,1,28,28) --> (-1, 3, 32, 32) [MNIST dims --> CIFAR10 dims]\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2) \n",
        "        # x = (-1,32,14,14) --> (-1, 64, 16, 16)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        # x = (-1,64,7,7) --> (-1, 64, 8, 8)\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        # x = (-1,64,7,7) --> (-1, 128, 4, 4)\n",
        "        x = x.view(-1, 128*4*4) #reshape before sending to fully-connected layer\n",
        "        # x = (-1,64*7*7) --> (-1, 128, 4, 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # x = (-1,1024) --> (-1, 2048)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        # x = (-1,1024) --> (-1, 2048)\n",
        "        x = self.fc2(x)\n",
        "        # x = (-1,10) --> (-1, 10)\n",
        "        return F.log_softmax(x,1)\n",
        "      \n",
        "model = ConvNetModelBest()\n",
        "#GPU: \n",
        "#model.cuda()\n",
        "\n",
        "#ConvNetModelBest Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "#optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n",
        "\n",
        "# Training the model\n",
        "# model.train()  # to set train mode for drop out\n",
        "# train_loss = []\n",
        "# train_accu = []\n",
        "# i = 0\n",
        "# for epoch in range(15):\n",
        "#     count = 0\n",
        "#     for data, target in train_loader:\n",
        "#       #GPU: \n",
        "#       data, target = data.cuda(), target.cuda()\n",
        "#       optimizer.zero_grad()\n",
        "#       output = model(data) # calls the forward function of model, is equivalent to model.forward(data)\n",
        "#       loss = F.nll_loss(output, target)\n",
        "#       loss.backward()    # calc gradients\n",
        "#       train_loss.append(loss.item())\n",
        "#       optimizer.step()   # update gradients\n",
        "#       prediction = output.data.max(1)[1]   # first column has actual prob.\n",
        "#       accuracy = np.sum(prediction.cpu().numpy()==target.cpu().numpy())/batch_size*100\n",
        "#       train_accu.append(accuracy)\n",
        "#       if i % 1000 == 0:\n",
        "#         print('Train Step: {}\\tLoss: {:.3f}\\tAccuracy: {:.3f}'.format(i, loss.item(), accuracy))\n",
        "#       i += 1\n",
        "\n",
        "# Part 2.4: Training Accuracy     \n",
        "# model.eval()\n",
        "# correctBest = 0\n",
        "# count = 0\n",
        "# for data, target in valid_loader:\n",
        "#   with torch.no_grad(): # so that computation graph history is not stored\n",
        "#     data, target = data.cuda(), target.cuda()\n",
        "#     output = model(data)\n",
        "#     prediction = output.data.max(1)[1]\n",
        "#     correctBest += prediction.eq(target.data).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NhAPHvAD3Cnu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "#matplotlib inline\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "alexnet = models.alexnet(pretrained=True)\n",
        "\n",
        "class AlexNetTrial(nn.Module):\n",
        "  \n",
        "    def __init__(self):\n",
        "        super(AlexNetTrial, self).__init__()\n",
        "        #features = list(vgg16(pretrained = True).features)[:23]\n",
        "        self.classifier = nn.Linear(512, 10) \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return F.log_softmax(out,1)\n",
        "        #x = self.features(x)\n",
        "        #return x\n",
        "            \n",
        "#vgg16 = models.vgg16(pretrained=True)\n",
        "\n",
        "model = alexnet\n",
        "#GPU: \n",
        "#model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}